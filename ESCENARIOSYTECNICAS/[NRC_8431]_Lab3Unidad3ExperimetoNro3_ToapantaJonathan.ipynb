{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QvyWNOSvsnzE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt #Gives us Graphics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "url = 'https://raw.githubusercontent.com/beespinosa1/Inter/main/Escenario3.csv'\n",
        "df = pd.read_csv(url)\n"
      ],
      "metadata": {
        "id": "_3U2OwkKssOq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns\n",
        "names =['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'dur',\n",
        "        'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service',\n",
        "        'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb',\n",
        "        'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len',\n",
        "        'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt', 'Dintpkt', 'tcprtt',\n",
        "        'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
        "        'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src',\n",
        "        'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm',\n",
        "        'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat', 'Label']\n",
        "df = pd.read_csv(url, names=names, low_memory=False)\n"
      ],
      "metadata": {
        "id": "LX6vjf2vssQx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle data\n",
        "dataframe = df.reindex(np.random.permutation(df.index)).copy()\n"
      ],
      "metadata": {
        "id": "AKJX1aW8ssS5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "def dfNormalize(df):\n",
        "    for feature_name in df.columns:\n",
        "        df.loc[:,feature_name]= pd.to_numeric(df.loc[:,feature_name], errors='coerce').fillna(0)\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()   \n",
        "        if (max_value - min_value) > 0:\n",
        "            df.loc[:,feature_name] = (df.loc[:,feature_name] - min_value) / (max_value - min_value)\n",
        "        else:\n",
        "            df.loc[:,feature_name] = (df.loc[:,feature_name]- min_value)    \n",
        "    return df\n"
      ],
      "metadata": {
        "id": "We5BUYW8ssVi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = dataframe.keys()\n",
        "data_to_process = dataframe[keys[4:len(keys)-1]].copy()\n",
        "x_normalized = dfNormalize(data_to_process)\n"
      ],
      "metadata": {
        "id": "tkMnfqLHssXh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_normalised, y, test_size=0.3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "kkjzzotzssaJ",
        "outputId": "7f907168-1e4a-448e-d31d-05a4a960bb27"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3370176596a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_normalised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_normalised' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to binary format\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "encoded_Y_train = encoder.transform(y_train)\n",
        "dummy_y_train = np_utils.to_categorical(encoded_Y_train)\n",
        "\n",
        "encoder.fit(y_test)\n",
        "encoded_Y_test = encoder.transform(y_test)\n",
        "dummy_y_test = np_utils.to_categorical(encoded_Y_test)"
      ],
      "metadata": {
        "id": "2FyTUOSQsscR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(64, 3, padding='same', input_shape=(x_normalised.shape[1],1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model.add(Conv1D(128, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model.add(Conv1D(256, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(dummy_y_train.shape[1]))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "rOeSaUvzu8Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train.values.reshape(X_train.shape[0],X_train.shape[1],1), dummy_y_train, epochs=10, batch_size=32, validation_data=(X_test.values.reshape(X_test.shape[0],X_test.shape[1],1), dummy_y_test))\n"
      ],
      "metadata": {
        "id": "80jWTFg8u_Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "score = model.evaluate(X_test.values.reshape(X_test.shape[0],X_test.shape[1],1), dummy_y_test, batch_size=32)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "GdghaOhFvBF5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}